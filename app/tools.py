import tempfile
import os
from typing import Tuple
import fitz
from docx import Document
from .utils import clean_text, check_file_size_bytes, safe_filename
from .config import GOOGLE_API_KEY, MAX_FILE_SIZE_MB
import google.generativeai as genai_old
import json
import hashlib
from google import genai

EVAL_CACHE = {}

if GOOGLE_API_KEY:
    genai_old.configure(api_key=GOOGLE_API_KEY)

client = genai.Client(api_key=GOOGLE_API_KEY)

def extract_text_from_pdf_bytes(content: bytes) -> str:
    with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:
        tmp.write(content)
        tmp_path = tmp.name
    text = ""
    try:
        with fitz.open(tmp_path) as pdf:
            for page in pdf:
                text += page.get_text()
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass
    return text

def extract_text_from_docx_bytes(content: bytes) -> str:
    with tempfile.NamedTemporaryFile(delete=False, suffix='.docx') as tmp:
        tmp.write(content)
        tmp_path = tmp.name
    text = ""
    try:
        doc = Document(tmp_path)
        text = '\n'.join([p.text for p in doc.paragraphs])
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass
    return text

def extract_text_from_txt_bytes(content: bytes) -> str:
    return content.decode('utf-8', errors='ignore')

async def extract_and_clean_from_uploadfile(upload_file) -> Tuple[bool, str]:
    raw = await upload_file.read()
    ok, msg = check_file_size_bytes(raw, MAX_FILE_SIZE_MB)
    if not ok:
        return False, msg

    suffix = os.path.splitext(safe_filename(upload_file.filename))[1].lower()
    if suffix == '.pdf':
        text = extract_text_from_pdf_bytes(raw)
    elif suffix in ('.doc', '.docx'):
        text = extract_text_from_docx_bytes(raw)
    elif suffix == '.txt':
        text = extract_text_from_txt_bytes(raw)
    else:
        return False, 'Äá»‹nh dáº¡ng khÃ´ng há»— trá»£. Há»— trá»£: PDF, DOCX, TXT.'

    cleaned = clean_text(text)
    if not cleaned:
        return False, 'KhÃ´ng thá»ƒ trÃ­ch xuáº¥t ná»™i dung tá»« file (file rá»—ng hoáº·c lá»—i).'
    return True, cleaned

def call_gemini_summarize(text: str, model_name: str = "gemini-2.5-flash") -> str:
    model = genai_old.GenerativeModel(model_name, tools=[])
    # YÃªu cáº§u model tá»± phÃ¡t hiá»‡n ngÃ´n ngá»¯ Ä‘áº§u vÃ o vÃ  tráº£ vá» báº£n tÃ³m táº¯t báº±ng cÃ¹ng ngÃ´n ngá»¯
    prompt = (
        "HÃ£y phÃ¡t hiá»‡n ngÃ´n ngá»¯ cá»§a vÄƒn báº£n dÆ°á»›i Ä‘Ã¢y. Sau Ä‘Ã³ táº¡o má»™t báº£n tÃ³m táº¯t ngáº¯n gá»n, rÃµ rÃ ng vÃ  Ä‘áº§y Ä‘á»§ báº±ng cÃ¹ng má»™t ngÃ´n ngá»¯.\n"
        f"Ná»™i dung:\n{text}"
    )
    resp = model.generate_content([prompt])
    return resp.text.strip()

def call_gemini_generate_mcqs(text: str, num_questions: int = 5, model_name: str = "gemini-2.5-flash") -> list:
    model = genai_old.GenerativeModel(model_name, tools=[])
    # YÃªu cáº§u model phÃ¡t hiá»‡n ngÃ´n ngá»¯ Ä‘áº§u vÃ o vÃ  sinh cÃ¢u há»i tráº¯c nghiá»‡m báº±ng cÃ¹ng ngÃ´n ngá»¯
    prompt = f"""
    Báº¡n lÃ  há»‡ thá»‘ng AI chuyÃªn sinh cÃ¢u há»i tráº¯c nghiá»‡m.
    TrÆ°á»›c tiÃªn hÃ£y xÃ¡c Ä‘á»‹nh ngÃ´n ngá»¯ cá»§a vÄƒn báº£n dÆ°á»›i Ä‘Ã¢y. Sau Ä‘Ã³ phÃ¢n tÃ­ch vÃ  sinh ra **{num_questions} cÃ¢u há»i tráº¯c nghiá»‡m cÃ³ 4 lá»±a chá»n** sá»­ dá»¥ng **chÃ­nh ngÃ´n ngá»¯ cá»§a vÄƒn báº£n Ä‘Ã³**, trong Ä‘Ã³ chá»‰ **má»™t lá»±a chá»n lÃ  Ä‘Ãºng**.

    ---

    ğŸ“˜ **Ngá»¯ cáº£nh gá»‘c (KHÃ”NG tÃ³m táº¯t, KHÃ”NG cáº¯t ngáº¯n):**
    {text}

    ---

    **HÆ°á»›ng dáº«n chi tiáº¿t:**
    1. XÃ¡c Ä‘á»‹nh **loáº¡i tÃ i liá»‡u** (vÃ­ dá»¥: há»c thuáº­t, ká»¹ thuáº­t, phÃ¡p luáº­t, giÃ¡o dá»¥c, mÃ´ táº£ dá»± Ã¡n,...).  
    2. Sinh cÃ¢u há»i phÃ¹ há»£p phong cÃ¡ch Ä‘Ã³.  
    3. Má»—i cÃ¢u há»i pháº£i:
        - Context khÃ´ng pháº£i lÃ  toÃ n bá»™ Ä‘oáº¡n vÄƒn, mÃ  lÃ  pháº§n liÃªn quan trá»±c tiáº¿p Ä‘áº¿n cÃ¢u há»i, dÃ i 2-3 cÃ¢u.
        - Pháº£n Ã¡nh Ä‘Ãºng thÃ´ng tin trong context (khÃ´ng suy diá»…n).
        - CÃ³ 1 Ä‘Ã¡p Ã¡n Ä‘Ãºng rÃµ rÃ ng, 3 Ä‘Ã¡p Ã¡n nhiá»…u cÃ¹ng chá»§ Ä‘á».
        - KhÃ´ng há»i trÃ¹ng Ã½ hoáº·c trÃ¹ng dá»¯ kiá»‡n.
        - CÃ¢u há»i vÃ  Ä‘Ã¡p Ã¡n pháº£i cÃ¹ng ngÃ´n ngá»¯ vá»›i vÄƒn báº£n gá»‘c.
    4. Distractors pháº£i há»£p lÃ½ â€” cÃ¹ng pháº¡m trÃ¹, khÃ´ng quÃ¡ sai.
    5. Náº¿u ná»™i dung context chá»‰ Ä‘á»§ cho 1-2 cÃ¢u há»i, tráº£ Ã­t hÆ¡n â€” khÃ´ng bá»‹a thÃªm.

    ---

    **Äá»‹nh dáº¡ng Ä‘áº§u ra JSON (duy nháº¥t, khÃ´ng cÃ³ vÄƒn báº£n nÃ o khÃ¡c):**
    [
    {{
        "context": "Äoáº¡n vÄƒn báº£n liÃªn quan Ä‘áº¿n cÃ¢u há»i (giá»¯ nguyÃªn, khÃ´ng tÃ³m táº¯t).",
        "question": "CÃ¢u há»i tráº¯c nghiá»‡m tiáº¿ng Viá»‡t rÃµ rÃ ng, cÃ³ má»™t Ä‘Ã¡p Ã¡n Ä‘Ãºng duy nháº¥t.",
        "options": [
            "A. ÄÃ¡p Ã¡n thá»© nháº¥t",
            "B. ÄÃ¡p Ã¡n thá»© hai",
            "C. ÄÃ¡p Ã¡n thá»© ba",
            "D. ÄÃ¡p Ã¡n thá»© tÆ°"
        ],
        "answer_letter": "B"
    }},
    ...
    ]

    **LÆ°u Ã½ báº¯t buá»™c:**
    - KHÃ”NG chÃ¨n markdown hoáº·c ```json.  
    - Náº¿u khÃ´ng thá»ƒ táº¡o há»£p lá»‡, tráº£ vá» `[]`.  
    - Giá»¯ nguyÃªn vÄƒn context, khÃ´ng Ä‘Æ°á»£c tÃ³m táº¯t hay cáº¯t ngáº¯n.
    """

    resp = model.generate_content([prompt])
    mcq_text = resp.text.strip()

    if mcq_text.startswith("```json"):
        mcq_text = mcq_text[7:]
    if mcq_text.startswith("```"):
        mcq_text = mcq_text[3:]
    if mcq_text.endswith("```"):
        mcq_text = mcq_text[:-3]
    mcq_text = mcq_text.strip()

    try:
        data = json.loads(mcq_text)
    except Exception:
        data = [{
            "context": text[:200] + "...",
            "question": "KhÃ´ng thá»ƒ táº¡o cÃ¢u há»i há»£p lá»‡ tá»« ná»™i dung nÃ y.",
            "options": ["Lá»—i", "Lá»—i", "Lá»—i", "Lá»—i"],
            "answer": "A. Lá»—i"
        }]
    return data

# tools.py
def extract_text_from_audio_with_gemini(file_path: str, model_name: str = "gemini-2.5-flash") -> str:
    """
    DÃ¹ng Gemini 2.5 (SDK má»›i) Ä‘á»ƒ tÃ³m táº¯t audio mÃ  khÃ´ng lá»—i ragStoreName.
    """
    prompt = (
        "HÃ£y nghe ká»¹ ná»™i dung trong Ä‘oáº¡n ghi Ã¢m nÃ y, "
        "phÃ¡t hiá»‡n ngÃ´n ngá»¯ Ä‘Æ°á»£c nÃ³i vÃ  tÃ³m táº¯t láº¡i ngáº¯n gá»n, rÃµ rÃ ng, Ä‘áº§y Ä‘á»§ báº±ng chÃ­nh ngÃ´n ngá»¯ Ä‘Ã³."
    )
    try:
        uploaded_file = client.files.upload(file=file_path)
        response = client.models.generate_content(
            model=model_name,
            contents=[prompt, uploaded_file]
        )
        return response.text.strip()
    except Exception as e:
        return f"[Lá»—i Gemini audio summarize] {str(e)}"


def extract_transcript_from_audio_with_gemini(file_path: str, model_name: str = "gemini-2.5-flash") -> str:
    """
    DÃ¹ng Gemini 2.5 (SDK má»›i) Ä‘á»ƒ chÃ©p láº¡i transcript audio mÃ  khÃ´ng lá»—i ragStoreName.
    """
    prompt = (
        "HÃ£y nghe toÃ n bá»™ Ä‘oáº¡n ghi Ã¢m nÃ y vÃ  chÃ©p láº¡i nguyÃªn vÄƒn ná»™i dung nÃ³i ra, "
        "giá»¯ nguyÃªn ngÃ´n ngá»¯ gá»‘c cá»§a ngÆ°á»i nÃ³i, khÃ´ng tÃ³m táº¯t, khÃ´ng bá» sÃ³t chi tiáº¿t."
    )
    try:
        uploaded_file = client.files.upload(file=file_path)
        response = client.models.generate_content(
            model=model_name,
            contents=[prompt, uploaded_file]
        )
        return response.text.strip()
    except Exception as e:
        return f"[Lá»—i Gemini transcript] {str(e)}"

def save_json_to_disk(obj, filename: str) -> str:
    out_path = os.path.join(tempfile.gettempdir(), filename)
    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
    return out_path


def get_hash_key(context, question):
    # Ã‰p toÃ n bá»™ pháº§n tá»­ vá» string, trÃ¡nh lá»—i tuple/bool/int
    def to_str(x):
        if isinstance(x, (list, tuple)):
            return " ".join(str(i) for i in x)
        return str(x)

    context_str = to_str(context)
    question_str = to_str(question)
    return hashlib.md5((context_str + question_str).encode("utf-8")).hexdigest()

def evaluate_mcq(mcq: dict, context_text: str = "") -> dict:
    global EVAL_CACHE
    key = get_hash_key(context_text, mcq.get("question", ""))
    if key in EVAL_CACHE:
        return EVAL_CACHE[key]

    question_data = [mcq]

    prompt = f"""
Báº¡n lÃ  chuyÃªn gia cÃ³ kinh nghiá»‡m trong viá»‡c Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cÃ¢u há»i tráº¯c nghiá»‡m (MCQs).

HÃ£y cháº¥m Ä‘iá»ƒm tá»«ng cÃ¢u há»i theo 4 tiÃªu chÃ­ sau (tá»•ng cá»™ng 100 Ä‘iá»ƒm):

1. **Accuracy (50 Ä‘iá»ƒm)**  
- Äá»™ chÃ­nh xÃ¡c cá»§a Ä‘Ã¡p Ã¡n Ä‘Ãºng so vá»›i ná»™i dung gá»‘c.  
- ÄÃºng hoÃ n toÃ n â†’ 50; Gáº§n Ä‘Ãºng â†’ 30-45; Sai hoáº·c khÃ´ng cÃ³ trong vÄƒn báº£n â†’ 0-25.  

2. **Alignment (25 Ä‘iá»ƒm)**  
- Má»©c Ä‘á»™ bÃ¡m sÃ¡t trá»ng tÃ¢m ná»™i dung.  
- ÄÃºng trá»ng tÃ¢m â†’ 20; Chi tiáº¿t phá»¥ hoáº·c suy luáº­n thÃªm â†’ 5-15; KhÃ´ng liÃªn quan â†’ 0.  

3. **Distractors (20 Ä‘iá»ƒm)**  
- Äá»™ há»£p lÃ½ cá»§a Ä‘Ã¡p Ã¡n sai.  
- Há»£p lÃ½, cÃ¹ng pháº¡m trÃ¹ â†’ 18-20; CÃ³ 1-2 lá»±a chá»n dá»… loáº¡i â†’ 10-17; Pháº§n lá»›n vÃ´ lÃ½ â†’ 0-9.  

4. **Clarity (5 Ä‘iá»ƒm)**  
- Äá»™ rÃµ rÃ ng, ngá»¯ phÃ¡p, máº¡ch láº¡c.  
- 5: RÃµ rÃ ng, Ä‘Ãºng ngá»¯ phÃ¡p; 4: HÆ¡i dÃ i dÃ²ng; 3: CÃ³ lá»—i nhá»; 2: Sai cáº¥u trÃºc; 1-0: MÆ¡ há»“ hoáº·c vÃ´ nghÄ©a. 

---

**YÃªu cáº§u káº¿t quáº£:**  
Chá»‰ tráº£ vá» **má»™t JSON há»£p lá»‡ duy nháº¥t**, khÃ´ng cÃ³ vÄƒn báº£n nÃ o khÃ¡c.

Cáº¥u trÃºc JSON:
{{
  "overall_score": <Ä‘iá»ƒm trung bÃ¬nh>,
  "details": [
    {{
      "question": "CÃ¢u há»i",
      "scores": {{
        "accuracy": <0-50>,
        "alignment": <0-25>,
        "distractors": <0-20>,
        "clarity": <0-5>,
        "total": <tá»•ng Ä‘iá»ƒm>
      }},
      "status": "accepted | need_review | rejected"
    }}
  ]
}}

Quy táº¯c phÃ¢n loáº¡i:
- total â‰¥ 80 â†’ accepted  
- 60 â‰¤ total < 80 â†’ need_review  
- total < 60 â†’ rejected  

---

**Context (ná»™i dung gá»‘c):**
{context_text}

**Danh sÃ¡ch cÃ¢u há»i:**
{json.dumps(question_data, ensure_ascii=False, indent=2)}
"""

    try:
        response = client.models.generate_content(
            model="gemini-2.5-flash",
            contents=prompt
        )
        text = response.text.strip()

        # LÃ m sáº¡ch output Ä‘á»ƒ parse JSON
        if text.startswith("```json"):
            text = text[7:]
        if text.endswith("```"):
            text = text[:-3]
        text = text.strip()

        data = json.loads(text)
        details = data.get("details", [{}])[0]
        scores = details.get("scores", {})
        total = scores.get("total", data.get("overall_score", 0))

        # Chuyá»ƒn káº¿t quáº£ sang dáº¡ng giá»‘ng cÅ© Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch há»‡ thá»‘ng
        mcq_result = dict(mcq)
        mcq_result["score"] = int(total)
        mcq_result["status"] = details.get("status", "need_review")
        mcq_result["_eval_breakdown"] = {
            "accuracy": scores.get("accuracy", 0),
            "alignment": scores.get("alignment", 0),
            "distractors": scores.get("distractors", 0),
            "clarity": scores.get("clarity", 0),
        }

        EVAL_CACHE[key] = mcq_result
        return mcq_result

    except Exception as e:
        fallback = dict(mcq)
        fallback["score"] = 0
        fallback["status"] = "rejected"
        fallback["_eval_breakdown"] = {
            "accuracy": 0,
            "alignment": 0,
            "distractors": 0,
            "clarity": 0,
        }
        fallback["comment"] = f"Lá»—i khi gá»i Gemini: {str(e)}"
        return fallback
